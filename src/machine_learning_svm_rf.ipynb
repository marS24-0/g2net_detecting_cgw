{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, ParameterGrid\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import rel_entr\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "df_feat = pd.read_csv('df_train', index_col=[\"record\", \"augm_idx\"])\n",
    "df_lbp = pd.read_csv('df_lbp_train', index_col=[\"record\", \"augm_idx\"])\n",
    "target = pd.DataFrame(pd.read_csv('targets_train', index_col=\"record\").join(df_lbp)[\"target\"])\n",
    "df = pd.concat([df_feat, df_lbp], axis=1)\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(list(itertools.product(np.arange(600), np.arange(10))), names=[\"record\", \"augm_idx\"])\n",
    "df.set_index(index, inplace=True)\n",
    "target.set_index(index, inplace=True)\n",
    "\n",
    "kernel = pd.read_csv('df_gram_tr.csv.gz', index_col=[0,1], header=[0,1])\n",
    "kernel.set_index(index, inplace=True)\n",
    "kernel.columns = index\n",
    "kernel = np.exp(-kernel/kernel.values.max())\n",
    "print(kernel.values.min())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base estimators + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "N_JOBS=-1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, train_size=4800, random_state=42, shuffle=False)\n",
    "\n",
    "feat_col_names = list(df_feat.columns.values)\n",
    "lbp_col_names = list(df_lbp.columns.values)\n",
    "\n",
    "feat_classifier = RandomForestClassifier()\n",
    "feat_col_trans = ColumnTransformer(transformers=[('selection', SimpleImputer(), feat_col_names)])\n",
    "scaler = StandardScaler()\n",
    "feat_pipe = Pipeline(steps=[('selection', feat_col_trans), ('preprocess', scaler), ('classifier', feat_classifier)])\n",
    "\n",
    "def kl_div(x, y):\n",
    "    fw = np.mean([np.sum(rel_entr(x[:512], y[:512])), np.sum(rel_entr(y[:512], x[:512]))])\n",
    "    bw = np.mean([np.sum(rel_entr(x[512:], y[512:])), np.sum(rel_entr(y[512:], x[512:]))])\n",
    "    return np.mean([fw, bw])\n",
    "\n",
    "lbp_classifier = SVC()\n",
    "lbp_pipe = lbp_classifier\n",
    "\n",
    "\n",
    "\n",
    "def cv_gen_zero(cv, df):\n",
    "    return [(df.loc[tr, :, :].index, df.loc[te, 0, :].index) for tr, te in cv.split(df.loc[:, 0, :])]\n",
    "\n",
    "def cv_gen(cv, df):\n",
    "    return [(df.loc[tr, :, :].index, df.loc[te, :, :].index) for tr, te in cv.split(df.loc[:, 0, :])]\n",
    "\n",
    "n_splits = 5\n",
    "cv = cv_gen(KFold(n_splits=n_splits, random_state=42, shuffle=True), X_train)\n",
    "cv_zero = cv_gen_zero(KFold(n_splits=n_splits, random_state=42, shuffle=True), X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbp classifier parameters TO UPDATE\n",
    "lbp_classifier_name = str(type(lbp_classifier)).split('.')[-1].split(\"'\")[0]\n",
    "lbp_params = {\n",
    "    # 'classifier__n_neighbors': [5, 10],\n",
    "    # 'classifier__weights': [\"uniform\", \"distance\"],\n",
    "    # 'classifier__n_jobs': [N_JOBS],\n",
    "    # 'classifier__metric': [kl_div]\n",
    "    'kernel': ['precomputed'],\n",
    "    'C': list(np.logspace(-1,1,3)),\n",
    "    'random_state': [42],\n",
    "    'probability': [True]\n",
    "}\n",
    "\n",
    "# feat classifier parameters TO UPDATE\n",
    "feat_classifier_name = str(type(feat_classifier)).split('.')[-1].split(\"'\")[0]\n",
    "feat_params = {\n",
    "    'classifier__n_estimators': [10000],\n",
    "    'classifier__criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'classifier__max_depth': [None, 5], # don't know if 10 is a good value\n",
    "    'classifier__max_features': [\"sqrt\", \"log2\", None],\n",
    "    'classifier__class_weight': [\"balanced\"],\n",
    "    'classifier__random_state': [42],\n",
    "    'classifier__n_jobs': [N_JOBS],\n",
    "}\n",
    "\n",
    "final_clf = LogisticRegression(random_state=42, n_jobs=N_JOBS)\n",
    "\n",
    "lbp_param_grid = [x for x in ParameterGrid(lbp_params)]\n",
    "feat_param_grid = [x for x in ParameterGrid(feat_params)]\n",
    "\n",
    "feat_predictions = []\n",
    "for i in range(len(feat_param_grid)):\n",
    "    feat_predictions.append([None]*n_splits)\n",
    "\n",
    "lbp_predictions = []\n",
    "for i in range(len(lbp_param_grid)):\n",
    "    lbp_predictions.append([None]*n_splits)\n",
    "\n",
    "results = []\n",
    "importances = []\n",
    "importances_lr = []\n",
    "for i, lbp_p in enumerate(lbp_param_grid):\n",
    "    lbp_pipe.set_params(**lbp_p)\n",
    "    for k, feat_p in tqdm(list(enumerate(feat_param_grid))):\n",
    "        feat_pipe.set_params(**feat_p)\n",
    "        scores = []\n",
    "        importances_c = []\n",
    "        feat_prob_te = pd.DataFrame(np.ones(X_train.shape[0])*2/3, index=X_train.index).rename(columns={0:\"feat_prob\"})\n",
    "        lbp_prob_te = pd.DataFrame(np.ones(X_train.shape[0])*2/3, index=X_train.index).rename(columns={0:\"lbp_prob\"})\n",
    "        for j, (train_index, test_index) in enumerate(cv):\n",
    "            # split\n",
    "            X_tr, X_te = X_train.loc[train_index], X_train.loc[test_index]\n",
    "            y_tr, y_te = y_train.loc[train_index], y_train.loc[test_index]\n",
    "\n",
    "            # fit and predict base estimators\n",
    "            \n",
    "            # use pre-calculated predictions for the feat classifier\n",
    "            try:\n",
    "                feat_prob_te.loc[test_index] = pd.read_csv(f\"feat_predictions_new/{feat_classifier_name}_prob_te_{k}_{j}\", index_col=0).values\n",
    "            except:\n",
    "                feat_pipe.fit(X_tr, y_tr)\n",
    "                feat_pred = feat_pipe.predict_proba(X_te)\n",
    "                feat_prob_te.loc[test_index] = feat_pred[:,1:2]\n",
    "                feat_prob_te.loc[test_index].to_csv(f\"feat_predictions_new/{feat_classifier_name}_prob_te_{k}_{j}\")\n",
    "                importances_c.append(feat_pipe['classifier'].feature_importances_)\n",
    "\n",
    "\n",
    "            # use pre-calculated predictions for the lbp classifier\n",
    "            try:\n",
    "                lbp_prob_te.loc[test_index] = pd.read_csv(f\"lbp_predictions_new/{lbp_classifier_name}_te_{i}_{j}\", index_col=0)\n",
    "            except:\n",
    "                X_tr_svm = kernel[train_index]\n",
    "                X_te_svm = X_tr_svm.loc[test_index]\n",
    "                X_tr_svm = X_tr_svm.loc[train_index]\n",
    "                lbp_pipe.fit(X_tr_svm, y_tr)\n",
    "                lbp_pred = lbp_pipe.predict_proba(X_te_svm)\n",
    "                lbp_prob_te.loc[test_index] = lbp_pred[:,1:2]\n",
    "                lbp_prob_te.loc[test_index].to_csv(f\"lbp_predictions_new/{lbp_classifier_name}_te_{i}_{j}\")\n",
    "\n",
    "        importances.append(importances_c)\n",
    "\n",
    "        importances_lr_c = []\n",
    "        for j, (train_index, test_index) in enumerate(cv_zero):\n",
    "            probs_te = pd.concat([lbp_prob_te, feat_prob_te], axis=1)\n",
    "            final_clf.fit(probs_te.loc[train_index], y_train.loc[train_index])\n",
    "            y_pr = final_clf.predict_proba(probs_te.loc[test_index])\n",
    "            y1 = [x[1] for x in y_pr]\n",
    "\n",
    "            # evaluate\n",
    "            scores.append(roc_auc_score(y_train.loc[test_index], y1))\n",
    "            importances_lr_c.append(final_clf.coef_)\n",
    "        r = (lbp_p, feat_p, np.mean(scores))\n",
    "        importances_lr.append(importances_lr_c)\n",
    "        results.append(r)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results_new/unsorted_{lbp_classifier_name}_{feat_classifier_name}.pickle', 'wb') as outf:\n",
    "    pickle.dump(obj=results, file=outf)\n",
    "\n",
    "sorted_results = sorted(results, key=lambda x: x[2], reverse=True)\n",
    "with open(f'results_new/{lbp_classifier_name}_{feat_classifier_name}.pickle', 'wb') as outf:\n",
    "    pickle.dump(obj=sorted_results, file=outf)\n",
    "\n",
    "with open(f'results_new/importances_lr_{lbp_classifier_name}_{feat_classifier_name}.pickle', 'wb') as outf:\n",
    "    pickle.dump(obj=importances_lr, file=outf)\n",
    "\n",
    "with open(f'results_new/importances_{lbp_classifier_name}_{feat_classifier_name}.pickle', 'wb') as outf:\n",
    "    pickle.dump(obj=importances, file=outf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
